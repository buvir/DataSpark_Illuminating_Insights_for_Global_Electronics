{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DataSpark: Illuminating Insights for Global Electronics***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.virtualenvs\\pythonproject\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.virtualenvs\\pythonproject\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: tzdata, pytz, numpy, pandas\n",
      "Successfully installed numpy-2.2.4 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\USER\\.virtualenvs\\pythonProject\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded with latin1 encoding!\n",
      "\n",
      "First 5 rows of df_Customers:\n",
      "   CustomerKey  Gender               Name            City State Code  \\\n",
      "0          301  Female      Lilly Harding  WANDEARAH EAST         SA   \n",
      "1          325  Female       Madison Hull      MOUNT BUDD         WA   \n",
      "2          554  Female      Claire Ferres       WINJALLOK        VIC   \n",
      "3          786    Male  Jai Poltpalingada    MIDDLE RIVER         SA   \n",
      "4         1042    Male    Aidan Pankhurst   TAWONGA SOUTH        VIC   \n",
      "\n",
      "               State Zip Code    Country  Continent    Birthday  \n",
      "0    South Australia     5523  Australia  Australia    7/3/1939  \n",
      "1  Western Australia     6522  Australia  Australia   9/27/1979  \n",
      "2           Victoria     3380  Australia  Australia   5/26/1947  \n",
      "3    South Australia     5223  Australia  Australia   9/17/1957  \n",
      "4           Victoria     3698  Australia  Australia  11/19/1965  \n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15266 entries, 0 to 15265\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   CustomerKey  15266 non-null  int64 \n",
      " 1   Gender       15266 non-null  object\n",
      " 2   Name         15266 non-null  object\n",
      " 3   City         15266 non-null  object\n",
      " 4   State Code   15256 non-null  object\n",
      " 5   State        15266 non-null  object\n",
      " 6   Zip Code     15266 non-null  object\n",
      " 7   Country      15266 non-null  object\n",
      " 8   Continent    15266 non-null  object\n",
      " 9   Birthday     15266 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# loading customers.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:/Users/USER/Desktop/DataSpark_Illuminating_Insights_for_Global_Electronics/Customers.csv\"\n",
    "\n",
    "# Method 1: Try common encodings automatically\n",
    "encodings = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df_Customers = pd.read_csv(file_path, encoding=encoding)\n",
    "        print(f\"Successfully loaded with {encoding} encoding!\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "\n",
    "# Method 2: Manual encoding specification (if automatic fails)\n",
    "# df_Customers = pd.read_csv(file_path, encoding='latin1')  # Most reliable fallback\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(\"\\nFirst 5 rows of df_Customers:\")\n",
    "print(df_Customers.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df_Customers.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerKey     int64\n",
       "Gender         object\n",
       "Name           object\n",
       "City           object\n",
       "State Code     object\n",
       "State          object\n",
       "Zip Code       object\n",
       "Country        object\n",
       "Continent      object\n",
       "Birthday       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Customers.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerKey             int64\n",
      "Gender         string[python]\n",
      "Name           string[python]\n",
      "City           string[python]\n",
      "State Code     string[python]\n",
      "State          string[python]\n",
      "Zip Code       string[python]\n",
      "Country        string[python]\n",
      "Continent      string[python]\n",
      "Birthday       datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical/text columns to string\n",
    "df_Customers[\"Gender\"] = df_Customers[\"Gender\"].astype(\"string\")\n",
    "df_Customers[\"Name\"] = df_Customers[\"Name\"].astype(\"string\")\n",
    "df_Customers[\"City\"] = df_Customers[\"City\"].astype(\"string\")\n",
    "df_Customers[\"State\"] = df_Customers[\"State\"].astype(\"string\")\n",
    "df_Customers[\"Country\"] = df_Customers[\"Country\"].astype(\"string\")\n",
    "df_Customers[\"Continent\"] = df_Customers[\"Continent\"].astype(\"string\")\n",
    "df_Customers[\"State Code\"] = df_Customers[\"State Code\"].astype(\"string\")\n",
    "df_Customers[\"Zip Code\"] = df_Customers[\"Zip Code\"].astype(\"string\")\n",
    "\n",
    "# Convert Birthday to datetime format\n",
    "df_Customers[\"Birthday\"] = pd.to_datetime(df_Customers[\"Birthday\"], format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "\n",
    "# Verify the changes\n",
    "print(df_Customers.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Customers_cleaned = df_Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerKey     int64\n",
      "Gender         object\n",
      "Name           object\n",
      "City           object\n",
      "State Code     object\n",
      "State          object\n",
      "Zip Code       object\n",
      "Country        object\n",
      "Continent      object\n",
      "Birthday       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify the changes\n",
    "print(df_Customers_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Customers_cleaned.to_csv('df_Customers_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Customers_cleaned = pd.read_csv('df_Customers_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerKey</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Birthday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lilly Harding</td>\n",
       "      <td>WANDEARAH EAST</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5523</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1939-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>Female</td>\n",
       "      <td>Madison Hull</td>\n",
       "      <td>MOUNT BUDD</td>\n",
       "      <td>WA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>6522</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1979-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554</td>\n",
       "      <td>Female</td>\n",
       "      <td>Claire Ferres</td>\n",
       "      <td>WINJALLOK</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3380</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1947-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>786</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jai Poltpalingada</td>\n",
       "      <td>MIDDLE RIVER</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5223</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1957-09-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1042</td>\n",
       "      <td>Male</td>\n",
       "      <td>Aidan Pankhurst</td>\n",
       "      <td>TAWONGA SOUTH</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3698</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1965-11-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerKey  Gender               Name            City State Code  \\\n",
       "0          301  Female      Lilly Harding  WANDEARAH EAST         SA   \n",
       "1          325  Female       Madison Hull      MOUNT BUDD         WA   \n",
       "2          554  Female      Claire Ferres       WINJALLOK        VIC   \n",
       "3          786    Male  Jai Poltpalingada    MIDDLE RIVER         SA   \n",
       "4         1042    Male    Aidan Pankhurst   TAWONGA SOUTH        VIC   \n",
       "\n",
       "               State Zip Code    Country  Continent    Birthday  \n",
       "0    South Australia     5523  Australia  Australia  1939-07-03  \n",
       "1  Western Australia     6522  Australia  Australia  1979-09-27  \n",
       "2           Victoria     3380  Australia  Australia  1947-05-26  \n",
       "3    South Australia     5223  Australia  Australia  1957-09-17  \n",
       "4           Victoria     3698  Australia  Australia  1965-11-19  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Customers_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.10-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\USER\\.virtualenvs\\pythonProject\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Collecting greenlet>=1\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\user\\.virtualenvs\\pythonproject\\lib\\site-packages (from sqlalchemy) (4.13.0)\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.1.1 sqlalchemy-2.0.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\USER\\.virtualenvs\\pythonProject\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'customers' does not exist. Creating it now...\n",
      "Table created successfully.\n",
      "Data inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "#push into pg sql , Customers_cleaned data _ final\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "        database=\"Global_Electronics_Data\",\n",
    "        user=\"postgres\",\n",
    "        password=\"sample12\"\n",
    "    )\n",
    "    connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Check if table exists\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT FROM information_schema.tables \n",
    "            WHERE table_name = 'customers'\n",
    "        );\n",
    "    \"\"\")\n",
    "    table_exists = cursor.fetchone()[0]\n",
    "\n",
    "    if not table_exists:\n",
    "        print(\"Table 'customers' does not exist. Creating it now...\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE customers (\n",
    "                CustomerKey INT PRIMARY KEY,\n",
    "                Gender VARCHAR(255),\n",
    "                Name TEXT,\n",
    "                City VARCHAR(255),\n",
    "                State_Code VARCHAR(255),\n",
    "                State VARCHAR(255),\n",
    "                Zip_Code VARCHAR(255),  -- Changed from INT to VARCHAR\n",
    "                Country VARCHAR(255),\n",
    "                Continent VARCHAR(255),\n",
    "                Birthday DATE\n",
    "            );\n",
    "        \"\"\")\n",
    "        print(\"Table created successfully.\")\n",
    "    \n",
    "    # Insert data\n",
    "    for index, row in df_Customers_cleaned.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO customers (CustomerKey, Gender, Name, City, State_Code, \n",
    "            State, Zip_Code, Country, Continent, Birthday) \n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (\n",
    "            row['CustomerKey'], row['Gender'], row['Name'], row['City'],\n",
    "            row['State Code'], row['State'], str(row['Zip Code']),  # Ensure Zip Code is string\n",
    "            row['Country'], row['Continent'], row['Birthday']\n",
    "        ))\n",
    "\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while interacting with the database: {e}\")\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15266 entries, 0 to 15265\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   CustomerKey  15266 non-null  int64 \n",
      " 1   Gender       15266 non-null  object\n",
      " 2   Name         15266 non-null  object\n",
      " 3   City         15266 non-null  object\n",
      " 4   State Code   15256 non-null  object\n",
      " 5   State        15266 non-null  object\n",
      " 6   Zip Code     15266 non-null  object\n",
      " 7   Country      15266 non-null  object\n",
      " 8   Continent    15266 non-null  object\n",
      " 9   Birthday     15266 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_Customers_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#push into pg sql , Customers_cleaned data\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "        database=\"Global_Electronics_Data\",\n",
    "        user=\"postgres\",\n",
    "        password=\"sample12\"\n",
    "    )\n",
    "    connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Check if table exists\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT FROM information_schema.tables \n",
    "            WHERE table_name = 'Customers'\n",
    "        );\n",
    "    \"\"\")\n",
    "    table_exists = cursor.fetchone()[0]\n",
    "\n",
    "    if not table_exists:\n",
    "        print(\"Table 'bus_routes' does not exist. Creating it now...\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE bus_routes (\n",
    "                CustomerKey PRIMARY KEY,\n",
    "                Gender VARCHAR(255),\n",
    "                Name TEXT,\n",
    "                City VARCHAR(255),\n",
    "                State_Code VARCHAR(255),\n",
    "                State VARCHAR(255),\n",
    "                Zip_Code INT,\n",
    "                Country VARCHAR(255),\n",
    "                Continent VARCHAR(255),\n",
    "                Birthday ,\n",
    "            );\n",
    "        \"\"\")\n",
    "        print(\"Table created successfully.\")\n",
    "    \n",
    "\n",
    "    # Insert data\n",
    "    for index,row in df_Customers_cleaned.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO bus_routes (CustomerKey, Gender, Name,City, State_Code, \n",
    "            State, Zip_Code, Country, Continent,Birthday) \n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (\n",
    "            row['CustomerKey'], row['Gender'], row['Name'], row['City'],\n",
    "            row['State Code'], row['State'],row['Zip Code'],row['Country'],row['Continent'],row['Birthday']\n",
    "        ))\n",
    "\n",
    "    connection.commit()\n",
    "    print(\"Data inserted successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while interacting with the database: {e}\")\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA' 'WA' 'VIC' 'QLD' 'NT' 'NSW' 'TAS' 'ACT' 'BC' 'QC' 'ON' 'AB' 'NS'\n",
      " 'SK' 'NU' 'PE' 'MB' 'NL' 'YT' 'NB' 'BB' 'RP' 'BY' 'BW' 'NW' 'NI' 'ST'\n",
      " 'MV' 'SN' 'TH' 'BE' 'HE' 'SL' 'SH' 'HB' 'HH' 'RA' 'IL' 'GY' 'AL' 'AQ'\n",
      " 'CA' 'NP' 'GD' 'FC' 'PA' 'PC' 'LI' 'MP' 'PI' 'HN' 'AU' 'PL' 'LO' 'BN'\n",
      " 'CE' 'LN' 'MQ' 'BO' 'BR' 'CO' 'MY' 'RC' 'VI' 'FE' 'RM' 'AG' 'IM' 'MI'\n",
      " 'PR' 'BG' 'RG' 'PN' 'SV' 'LU' 'CN' 'TN' 'LE' 'PD' 'BI' 'CH' 'GE' 'TO'\n",
      " 'VV' 'CZ' 'AN' 'PG' 'LT' 'BL' 'TV' 'PV' 'MN' 'VA' 'PT' 'SI' 'MS' 'CT'\n",
      " 'BS' 'SS' 'RO' 'CR' 'FI' 'GR' 'IS' 'SO' 'VE' 'OR' 'ME' 'VR' 'CS' 'BZ'\n",
      " 'NO' 'AV' 'TA' 'VC' 'GO' 'MO' 'FR' 'FG' 'TE' 'BA' 'UD' 'AP' 'TP' 'RE'\n",
      " 'PO' nan 'AT' 'SR' 'RI' 'TS' 'KR' 'MT' 'PZ' 'MC' 'VT' 'AR' 'AO' 'CB' 'LC'\n",
      " 'SP' 'RN' 'FO' 'TR' 'UT' 'NH' 'DR' 'ZH' 'FL' 'OV' 'ZE' 'Falkirk'\n",
      " 'Ceredigion' 'North East Lincolnshire' 'Aberdeenshire' 'York'\n",
      " 'Pembrokeshire' 'Leicester' 'Highland' 'Tendring' 'Horsham' 'Newport'\n",
      " 'Bristol' 'Newark and Sherwood' 'Argyllshire' 'Lincoln' 'Tamworth'\n",
      " 'Fylde' 'Lewes' 'Rhondda Cynon Taf' 'Bromsgrove' 'Ripon' 'Cornwall'\n",
      " 'South Lanarkshire' 'Shropshire' 'Perth and Kinross' 'Crawley'\n",
      " 'Staffordshire' 'Mendip' 'Forest Heath' 'Moray' 'Bracknell Forest'\n",
      " 'Anglesey' 'Bolsover' 'Calderdale' 'Ashford' 'Sussex' 'Darlington'\n",
      " 'East Devon' 'Monmouthshire' 'Gloucester' 'Mid Devon' 'Somerset'\n",
      " 'Hereford' 'Bath and North East Somerset' 'Bassetlaw' 'Christchurch'\n",
      " 'West Berkshire' 'Gwynedd' 'Suffolk' 'Tewkesbury' 'Colchester'\n",
      " 'Llandrindod Wells' 'Harrogate' 'Winchester' 'Angus' 'Derbyshire Dales'\n",
      " 'Dacorum' 'Suffolk Coastal' 'Wiltshire' 'Leeds' 'Kennet' 'Hampshire'\n",
      " 'Norfolk' 'Northumberland' 'Doncaster' 'Purbeck' 'Wyre Forest'\n",
      " 'Redcar & Cleveland' 'West Dorset' 'Ipswich' 'Powys' 'Midlothian' 'Fife'\n",
      " 'North Ayrshire' 'Carmarthenshire' 'Birmingham' 'South Oxfordshire'\n",
      " 'North Yorkshire' 'Cheshire West and Chester' 'Scottish Borders'\n",
      " 'Lichfield' 'Rushcliffe' 'Arun' 'Dumfriesshire' 'Wakefield'\n",
      " 'Denbighshire' 'Plymouth' 'St Edmundsbury' 'Edinburgh' 'Liverpool' 'Kent'\n",
      " 'Warwick' 'Gedling' 'Shetland' 'Flintshire' 'Gravesham'\n",
      " 'Central Bedfordshire' 'North Dorset' 'Lancaster' 'Breckland'\n",
      " 'East Riding of Yorkshire' 'Exeter' 'Vale of White Horse' 'Cherwell'\n",
      " 'South Holland' 'South Lakeland' 'Stroud' 'Orkney Islands' 'West Lindsey'\n",
      " 'Stratford-on-Avon' 'West Oxfordshire' 'Bedford' 'Rother' 'Isle of Man'\n",
      " 'Swindon' 'Charnwood' 'Waverley' 'Wolverhampton' 'Aylesbury Vale'\n",
      " 'Merton' 'Sevenoaks' 'Allerdale' 'Bolton' 'Selby' 'Berkshire' 'Copeland'\n",
      " 'Chelmsford' 'South Kesteven' 'Cheshire East' 'Boston' 'County Durham'\n",
      " 'Mid Suffolk' 'Wandsworth' 'West Dunbartonshire' 'Erewash' 'Babergh'\n",
      " 'South Hams' 'Wigan' 'South Ayrshire' 'Rotherham' 'Isle of Wight'\n",
      " 'Cotswold' 'Worcester' 'Rutland' 'East Northamptonshire' 'Rugby'\n",
      " 'Stirling' 'North Kesteven' 'Comhairle nan Eilean Siar' 'Walsall'\n",
      " 'Knowsley' 'South Somerset' 'North Lincolnshire' 'South Norfolk'\n",
      " 'Aberdeen' 'Welwyn Hatfield' 'Kirkcudbrightshire' 'Carlisle' 'Hillingdon'\n",
      " 'West Norfolk' 'Kirklees' 'New Forest' 'Swansea' 'Craven' 'Camden'\n",
      " 'North Somerset' 'Teignbridge' 'Melton' 'Conwy' 'Enfield' 'Glasgow'\n",
      " 'Braintree' 'Chichester' 'North Hertfordshire' 'East Lothian'\n",
      " 'Renfrewshire' 'Eden' 'Uttlesford' 'Mid Sussex' 'Peterborough' 'Ashfield'\n",
      " 'Redbridge' 'Sheffield' 'Newcastle' 'Harlow' 'East Hampshire'\n",
      " 'Caerphilly' 'North Warwickshire' 'Brentwood' 'Tameside'\n",
      " 'Brighton and Hove' 'Rossendale' 'Swale' 'Sutton' 'Huntingdonshire'\n",
      " 'St Albans' 'Dudley' 'East Hertfordshire' 'Guildford' 'Cambridge'\n",
      " 'Woking' 'Daventry' 'Vale of Glamorgan' 'East Ayrshire' 'Bradford'\n",
      " 'South Buckinghamshire' 'Merthyr Tydfil' 'West Lothian' 'East Lindsey'\n",
      " 'Hambleton' 'Tower Hamlets' 'Test Valley' 'Dartford' 'Sunderland'\n",
      " 'Medway' 'Rochdale' 'Bury' 'Oxford' 'Bridgend' 'South Derbyshire'\n",
      " 'Milton Keynes' 'Southampton' 'Wokingham' 'Nottingham' 'Stevenage'\n",
      " 'Wirral' 'Dundee' 'Amber Valley' 'Harrow' 'East Dorset' 'Maidstone'\n",
      " 'Wigtownshire' 'Gateshead' 'Telford and Wrekin' 'Wellingborough'\n",
      " 'Runnymede' 'Wrexham' 'Cannock Chase' 'Kensington and Chelsea'\n",
      " 'South Gloucestershire' 'Wycombe' 'South Staffordshire' 'Sandwell'\n",
      " 'Bromley' 'Torridge' 'Burnley' 'Sefton' 'Ribble Valley' 'Chiltern'\n",
      " 'Hastings' 'East Staffordshire' 'Barnet' 'Reigate and Banstead'\n",
      " 'Basildon' 'Tandridge' 'Westminster' 'Warrington' 'West Lancashire'\n",
      " 'Preston' 'Canterbury' 'Wealden' 'Havering' 'West Devon' 'Islington'\n",
      " 'Wyre' 'Kinross-Shire' 'Waveney' 'North Lanarkshire' 'Ely'\n",
      " 'Neath Port Talbot' 'Nuneaton & Bedworth' 'Chesterfield' 'Mole Valley'\n",
      " 'South Northamptonshire' 'Broxbourne' 'Cardiff' 'Hackney' 'Redditch'\n",
      " 'Tunbridge Wells' 'Haringey' 'Malvern Hills' 'Broxtowe' 'Spelthorne'\n",
      " 'Coventry' 'Newmarket' 'Lanarkshire' 'East Dunbartonshire'\n",
      " 'Stockton-on-Tees' 'NC' 'MD' 'HI' 'NY' 'TX' 'GA' 'DE' 'WI' 'KS' 'NV' 'MA'\n",
      " 'NJ' 'OH' 'IA' 'KY' 'DC' 'OK' 'ID' 'AZ' 'IN' 'WV' 'NE' 'LA' 'AK' 'ND'\n",
      " 'SC' 'NM' 'SD' 'WY']\n"
     ]
    }
   ],
   "source": [
    "print(df_Customers[\"State Code\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         5523\n",
      "1         6522\n",
      "2         3380\n",
      "3         5223\n",
      "4         3698\n",
      "         ...  \n",
      "15261    77017\n",
      "15262    22101\n",
      "15263    28405\n",
      "15264    92501\n",
      "15265    48302\n",
      "Name: Zip Code, Length: 15266, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_Customers[\"Zip Code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerKey             int64\n",
      "Gender         string[python]\n",
      "Name           string[python]\n",
      "City           string[python]\n",
      "State Code     string[python]\n",
      "State          string[python]\n",
      "Zip Code       string[python]\n",
      "Country        string[python]\n",
      "Continent      string[python]\n",
      "Birthday       datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_Customers.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15266 entries, 0 to 15265\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   CustomerKey  15266 non-null  int64         \n",
      " 1   Gender       15266 non-null  string        \n",
      " 2   Name         15266 non-null  string        \n",
      " 3   City         15266 non-null  string        \n",
      " 4   State Code   15256 non-null  string        \n",
      " 5   State        15266 non-null  string        \n",
      " 6   Zip Code     15266 non-null  string        \n",
      " 7   Country      15266 non-null  string        \n",
      " 8   Continent    15266 non-null  string        \n",
      " 9   Birthday     15266 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), string(8)\n",
      "memory usage: 1.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_Customers.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Customers.to_csv(\"customers_cleaned.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  CustomerKey  Gender               Name  \\\n",
      "0               0          301  Female      Lilly Harding   \n",
      "1               1          325  Female       Madison Hull   \n",
      "2               2          554  Female      Claire Ferres   \n",
      "3               3          786    Male  Jai Poltpalingada   \n",
      "4               4         1042    Male    Aidan Pankhurst   \n",
      "...           ...          ...     ...                ...   \n",
      "15261       15261      2099600  Female     Denisa Duková   \n",
      "15262       15262      2099618    Male   Justin Solórzano   \n",
      "15263       15263      2099758    Male    Svend Petrussen   \n",
      "15264       15264      2099862  Female       Lorenza Rush   \n",
      "15265       15265      2099937    Male   Zygmunt Kaminski   \n",
      "\n",
      "                      City State Code              State Zip Code  \\\n",
      "0           WANDEARAH EAST         SA    South Australia     5523   \n",
      "1               MOUNT BUDD         WA  Western Australia     6522   \n",
      "2                WINJALLOK        VIC           Victoria     3380   \n",
      "3             MIDDLE RIVER         SA    South Australia     5223   \n",
      "4            TAWONGA SOUTH        VIC           Victoria     3698   \n",
      "...                    ...        ...                ...      ...   \n",
      "15261              Houston         TX              Texas    77017   \n",
      "15262               Mclean         VA           Virginia    22101   \n",
      "15263           Wilmington         NC     North Carolina    28405   \n",
      "15264            Riverside         CA         California    92501   \n",
      "15265  Bloomfield Township         MI           Michigan    48302   \n",
      "\n",
      "             Country      Continent    Birthday  \n",
      "0          Australia      Australia  1939-07-03  \n",
      "1          Australia      Australia  1979-09-27  \n",
      "2          Australia      Australia  1947-05-26  \n",
      "3          Australia      Australia  1957-09-17  \n",
      "4          Australia      Australia  1965-11-19  \n",
      "...              ...            ...         ...  \n",
      "15261  United States  North America  1936-03-25  \n",
      "15262  United States  North America  1992-02-16  \n",
      "15263  United States  North America  1937-11-09  \n",
      "15264  United States  North America  1937-10-12  \n",
      "15265  United States  North America  1965-08-18  \n",
      "\n",
      "[15266 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV\n",
    "df_customers_cleaned = pd.read_csv(\"customers_cleaned.csv\")\n",
    "\n",
    "# Display the entire DataFrame (if it's small)\n",
    "print(df_customers_cleaned)  # Shows all rows without truncation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15266 entries, 0 to 15265\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   15266 non-null  int64 \n",
      " 1   CustomerKey  15266 non-null  int64 \n",
      " 2   Gender       15266 non-null  object\n",
      " 3   Name         15266 non-null  object\n",
      " 4   City         15266 non-null  object\n",
      " 5   State Code   15256 non-null  object\n",
      " 6   State        15266 non-null  object\n",
      " 7   Zip Code     15266 non-null  object\n",
      " 8   Country      15266 non-null  object\n",
      " 9   Continent    15266 non-null  object\n",
      " 10  Birthday     15266 non-null  object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_customers_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Products****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded with utf-8 encoding!\n",
      "\n",
      "First 5 rows of df_Products:\n",
      "   ProductKey                         Product Name    Brand   Color  \\\n",
      "0           1  Contoso 512MB MP3 Player E51 Silver  Contoso  Silver   \n",
      "1           2    Contoso 512MB MP3 Player E51 Blue  Contoso    Blue   \n",
      "2           3     Contoso 1G MP3 Player E100 White  Contoso   White   \n",
      "3           4    Contoso 2G MP3 Player E200 Silver  Contoso  Silver   \n",
      "4           5       Contoso 2G MP3 Player E200 Red  Contoso     Red   \n",
      "\n",
      "  Unit Cost USD Unit Price USD  SubcategoryKey Subcategory  CategoryKey  \\\n",
      "0        $6.62         $12.99              101     MP4&MP3            1   \n",
      "1        $6.62         $12.99              101     MP4&MP3            1   \n",
      "2        $7.40         $14.52              101     MP4&MP3            1   \n",
      "3       $11.00         $21.57              101     MP4&MP3            1   \n",
      "4       $11.00         $21.57              101     MP4&MP3            1   \n",
      "\n",
      "  Category  \n",
      "0    Audio  \n",
      "1    Audio  \n",
      "2    Audio  \n",
      "3    Audio  \n",
      "4    Audio  \n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   ProductKey      2517 non-null   int64 \n",
      " 1   Product Name    2517 non-null   object\n",
      " 2   Brand           2517 non-null   object\n",
      " 3   Color           2517 non-null   object\n",
      " 4   Unit Cost USD   2517 non-null   object\n",
      " 5   Unit Price USD  2517 non-null   object\n",
      " 6   SubcategoryKey  2517 non-null   int64 \n",
      " 7   Subcategory     2517 non-null   object\n",
      " 8   CategoryKey     2517 non-null   int64 \n",
      " 9   Category        2517 non-null   object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 196.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# loading Products.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:/Users/USER/Desktop/DataSpark_Illuminating_Insights_for_Global_Electronics/Products.csv\"\n",
    "\n",
    "# Method 1: Try common encodings automatically\n",
    "encodings = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df_Products = pd.read_csv(file_path, encoding=encoding)\n",
    "        print(f\"Successfully loaded with {encoding} encoding!\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "\n",
    "# Method 2: Manual encoding specification (if automatic fails)\n",
    "# df_Products = pd.read_csv(file_path, encoding='latin1')  # Most reliable fallback\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(\"\\nFirst 5 rows of df_Products:\")\n",
    "print(df_Products.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df_Products.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductKey                 int64\n",
      "Product Name      string[python]\n",
      "Brand             string[python]\n",
      "Color             string[python]\n",
      "Unit Cost USD            float64\n",
      "Unit Price USD           float64\n",
      "SubcategoryKey             int64\n",
      "Subcategory       string[python]\n",
      "CategoryKey                int64\n",
      "Category          string[python]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical/text columns to string\n",
    "df_Products[\"Product Name\"] = df_Products[\"Product Name\"].astype(\"string\")\n",
    "df_Products[\"Brand\"] = df_Products[\"Brand\"].astype(\"string\")\n",
    "df_Products[\"Color\"] = df_Products[\"Color\"].astype(\"string\")\n",
    "df_Products[\"Subcategory\"] = df_Products[\"Subcategory\"].astype(\"string\")\n",
    "df_Products[\"Category\"] = df_Products[\"Category\"].astype(\"string\")\n",
    "\n",
    "# Convert currency columns to numeric (removing $ sign first)\n",
    "df_Products[\"Unit Cost USD\"] = df_Products[\"Unit Cost USD\"].replace('[\\$,]', '', regex=True).astype(float)\n",
    "df_Products[\"Unit Price USD\"] = df_Products[\"Unit Price USD\"].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Verify the changes\n",
    "\n",
    "print(df_Products.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ProductKey      2517 non-null   int64  \n",
      " 1   Product Name    2517 non-null   string \n",
      " 2   Brand           2517 non-null   string \n",
      " 3   Color           2517 non-null   string \n",
      " 4   Unit Cost USD   2517 non-null   float64\n",
      " 5   Unit Price USD  2517 non-null   float64\n",
      " 6   SubcategoryKey  2517 non-null   int64  \n",
      " 7   Subcategory     2517 non-null   string \n",
      " 8   CategoryKey     2517 non-null   int64  \n",
      " 9   Category        2517 non-null   string \n",
      "dtypes: float64(2), int64(3), string(5)\n",
      "memory usage: 196.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_Products.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Products_cleaned=df_Products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductKey                         Product Name    Brand   Color  \\\n",
      "0           1  Contoso 512MB MP3 Player E51 Silver  Contoso  Silver   \n",
      "1           2    Contoso 512MB MP3 Player E51 Blue  Contoso    Blue   \n",
      "2           3     Contoso 1G MP3 Player E100 White  Contoso   White   \n",
      "3           4    Contoso 2G MP3 Player E200 Silver  Contoso  Silver   \n",
      "4           5       Contoso 2G MP3 Player E200 Red  Contoso     Red   \n",
      "\n",
      "   Unit Cost USD  Unit Price USD  SubcategoryKey Subcategory  CategoryKey  \\\n",
      "0           6.62           12.99             101     MP4&MP3            1   \n",
      "1           6.62           12.99             101     MP4&MP3            1   \n",
      "2           7.40           14.52             101     MP4&MP3            1   \n",
      "3          11.00           21.57             101     MP4&MP3            1   \n",
      "4          11.00           21.57             101     MP4&MP3            1   \n",
      "\n",
      "  Category  \n",
      "0    Audio  \n",
      "1    Audio  \n",
      "2    Audio  \n",
      "3    Audio  \n",
      "4    Audio  \n"
     ]
    }
   ],
   "source": [
    "print(Products_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ProductKey      2517 non-null   int64  \n",
      " 1   Product Name    2517 non-null   string \n",
      " 2   Brand           2517 non-null   string \n",
      " 3   Color           2517 non-null   string \n",
      " 4   Unit Cost USD   2517 non-null   float64\n",
      " 5   Unit Price USD  2517 non-null   float64\n",
      " 6   SubcategoryKey  2517 non-null   int64  \n",
      " 7   Subcategory     2517 non-null   string \n",
      " 8   CategoryKey     2517 non-null   int64  \n",
      " 9   Category        2517 non-null   string \n",
      "dtypes: float64(2), int64(3), string(5)\n",
      "memory usage: 196.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Products_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Products_cleaned.to_csv(\"Products_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ProductKey                                   Product Name    Brand  \\\n",
      "0              1            Contoso 512MB MP3 Player E51 Silver  Contoso   \n",
      "1              2              Contoso 512MB MP3 Player E51 Blue  Contoso   \n",
      "2              3               Contoso 1G MP3 Player E100 White  Contoso   \n",
      "3              4              Contoso 2G MP3 Player E200 Silver  Contoso   \n",
      "4              5                 Contoso 2G MP3 Player E200 Red  Contoso   \n",
      "...          ...                                            ...      ...   \n",
      "2512        2513    Contoso Bluetooth Active Headphones L15 Red  Contoso   \n",
      "2513        2514  Contoso Bluetooth Active Headphones L15 White  Contoso   \n",
      "2514        2515             Contoso In-Line Coupler E180 White  Contoso   \n",
      "2515        2516             Contoso In-Line Coupler E180 Black  Contoso   \n",
      "2516        2517            Contoso In-Line Coupler E180 Silver  Contoso   \n",
      "\n",
      "       Color  Unit Cost USD  Unit Price USD  SubcategoryKey  \\\n",
      "0     Silver           6.62           12.99             101   \n",
      "1       Blue           6.62           12.99             101   \n",
      "2      White           7.40           14.52             101   \n",
      "3     Silver          11.00           21.57             101   \n",
      "4        Red          11.00           21.57             101   \n",
      "...      ...            ...             ...             ...   \n",
      "2512     Red          43.07          129.99             505   \n",
      "2513   White          43.07          129.99             505   \n",
      "2514   White           1.71            3.35             505   \n",
      "2515   Black           1.71            3.35             505   \n",
      "2516  Silver           1.71            3.35             505   \n",
      "\n",
      "                  Subcategory  CategoryKey     Category  \n",
      "0                     MP4&MP3            1        Audio  \n",
      "1                     MP4&MP3            1        Audio  \n",
      "2                     MP4&MP3            1        Audio  \n",
      "3                     MP4&MP3            1        Audio  \n",
      "4                     MP4&MP3            1        Audio  \n",
      "...                       ...          ...          ...  \n",
      "2512  Cell phones Accessories            5  Cell phones  \n",
      "2513  Cell phones Accessories            5  Cell phones  \n",
      "2514  Cell phones Accessories            5  Cell phones  \n",
      "2515  Cell phones Accessories            5  Cell phones  \n",
      "2516  Cell phones Accessories            5  Cell phones  \n",
      "\n",
      "[2517 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV\n",
    "Products_cleaned = pd.read_csv(\"Products_cleaned.csv\")\n",
    "\n",
    "# Display the entire DataFrame (if it's small)\n",
    "print(Products_cleaned)  # Shows all rows without truncation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ProductKey      2517 non-null   int64  \n",
      " 1   Product Name    2517 non-null   string \n",
      " 2   Brand           2517 non-null   string \n",
      " 3   Color           2517 non-null   string \n",
      " 4   Unit Cost USD   2517 non-null   float64\n",
      " 5   Unit Price USD  2517 non-null   float64\n",
      " 6   SubcategoryKey  2517 non-null   int64  \n",
      " 7   Subcategory     2517 non-null   string \n",
      " 8   CategoryKey     2517 non-null   int64  \n",
      " 9   Category        2517 non-null   string \n",
      "dtypes: float64(2), int64(3), string(5)\n",
      "memory usage: 196.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Products_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Products' does not exist. Creating it now...\n",
      "Table created successfully.\n",
      "Successfully inserted 2517 records into Products table.\n"
     ]
    }
   ],
   "source": [
    "#push into pg sql , Products_cleaned data\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "try:\n",
    "    # Connect to PostgreSQL\n",
    "    connection = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\",\n",
    "        database=\"Global_Electronics_Data\",\n",
    "        user=\"postgres\",\n",
    "        password=\"sample12\"\n",
    "    )\n",
    "    connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Check if table exists\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT EXISTS (\n",
    "            SELECT FROM information_schema.tables \n",
    "            WHERE table_name = 'Products'\n",
    "        );\n",
    "    \"\"\")\n",
    "    table_exists = cursor.fetchone()[0]\n",
    "\n",
    "    if not table_exists:\n",
    "        print(\"Table 'Products' does not exist. Creating it now...\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE Products (\n",
    "                ProductKey INT PRIMARY KEY,\n",
    "                Product_Name VARCHAR(255),\n",
    "                Brand VARCHAR(255),\n",
    "                Color VARCHAR(255),\n",
    "                Unit_Cost_USD NUMERIC(10,2),\n",
    "                Unit_Price_USD NUMERIC(10,2),\n",
    "                SubcategoryKey INT,\n",
    "                Subcategory VARCHAR(255),\n",
    "                CategoryKey INT,\n",
    "                Category VARCHAR(255)\n",
    "            );\n",
    "        \"\"\")\n",
    "        print(\"Table created successfully.\")\n",
    "\n",
    "    # Insert data - using parameterized query\n",
    "    for index, row in Products_cleaned.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Products (\n",
    "                ProductKey, Product_Name, Brand, Color,\n",
    "                Unit_Cost_USD, Unit_Price_USD,\n",
    "                SubcategoryKey, Subcategory,\n",
    "                CategoryKey, Category\n",
    "            ) \n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", (\n",
    "            row['ProductKey'], row['Product Name'], row['Brand'], row['Color'],\n",
    "            row['Unit Cost USD'], row['Unit Price USD'],\n",
    "            row['SubcategoryKey'], row['Subcategory'],\n",
    "            row['CategoryKey'], row['Category']\n",
    "        ))\n",
    "\n",
    "    connection.commit()\n",
    "    print(f\"Successfully inserted {len(Products_cleaned)} records into Products table.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while interacting with the database: {e}\")\n",
    "    if connection:\n",
    "        connection.rollback()\n",
    "\n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Stores*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded with utf-8 encoding!\n",
      "\n",
      "First 5 rows of df_Stores:\n",
      "   StoreKey    Country                         State  Square Meters  Open Date\n",
      "0         1  Australia  Australian Capital Territory          595.0   1/1/2008\n",
      "1         2  Australia            Northern Territory          665.0  1/12/2008\n",
      "2         3  Australia               South Australia         2000.0   1/7/2012\n",
      "3         4  Australia                      Tasmania         2000.0   1/1/2010\n",
      "4         5  Australia                      Victoria         2000.0  12/9/2015\n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   StoreKey       67 non-null     int64  \n",
      " 1   Country        67 non-null     object \n",
      " 2   State          67 non-null     object \n",
      " 3   Square Meters  66 non-null     float64\n",
      " 4   Open Date      67 non-null     object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 2.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# loading Stores.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:/Users/USER/Desktop/DataSpark_Illuminating_Insights_for_Global_Electronics/Stores.csv\"\n",
    "\n",
    "# Method 1: Try common encodings automatically\n",
    "encodings = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df_Stores = pd.read_csv(file_path, encoding=encoding)\n",
    "        print(f\"Successfully loaded with {encoding} encoding!\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "\n",
    "# Method 2: Manual encoding specification (if automatic fails)\n",
    "# df_Stores = pd.read_csv(file_path, encoding='latin1')  # Most reliable fallback\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(\"\\nFirst 5 rows of df_Stores:\")\n",
    "print(df_Stores.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df_Stores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StoreKey                  int64\n",
      "Country          string[python]\n",
      "State            string[python]\n",
      "Square Meters           float64\n",
      "Open Date        datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical/text columns to string\n",
    "df_Stores[\"Country\"] = df_Stores[\"Country\"].astype(\"string\")\n",
    "df_Stores[\"State\"] = df_Stores[\"State\"].astype(\"string\")\n",
    "\n",
    "# Convert numeric columns\n",
    "df_Stores[\"Square Meters\"] = df_Stores[\"Square Meters\"].astype(float)  # Already appears to be numeric\n",
    "\n",
    "# Convert date column to datetime\n",
    "df_Stores[\"Open Date\"] = pd.to_datetime(df_Stores[\"Open Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "# Verify the changes\n",
    "print(df_Stores.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   StoreKey       67 non-null     int64         \n",
      " 1   Country        67 non-null     string        \n",
      " 2   State          67 non-null     string        \n",
      " 3   Square Meters  66 non-null     float64       \n",
      " 4   Open Date      59 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), string(2)\n",
      "memory usage: 2.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_Stores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy method (recommended)\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://postgres:sample12@localhost:5432/Global_Electronics_Data')\n",
    "\n",
    "df_Stores.to_sql(\n",
    "    'stores',\n",
    "    engine,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    dtype={\n",
    "        'StoreKey': 'INTEGER PRIMARY KEY',\n",
    "        'Country': 'VARCHAR(255)',\n",
    "        'State': 'VARCHAR(255)',\n",
    "        'Square Meters': 'NUMERIC(10,2)',\n",
    "        'Open Date': 'DATE'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Or using psycopg2 (alternative method)\n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"Global_Electronics_Data\",\n",
    "    user=\"postgres\",\n",
    "    password=\"sample12\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table if not exists\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stores (\n",
    "        StoreKey INT PRIMARY KEY,\n",
    "        Country VARCHAR(255),\n",
    "        State VARCHAR(255),\n",
    "        Square_Meters NUMERIC(10,2),\n",
    "        Open_Date DATE\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Insert data\n",
    "for _, row in df_Stores.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO stores (StoreKey, Country, State, Square_Meters, Open_Date)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        row['StoreKey'],\n",
    "        row['Country'],\n",
    "        row['State'],\n",
    "        row['Square Meters'],\n",
    "        row['Open Date']\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exchange_Rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded with utf-8 encoding!\n",
      "\n",
      "First 5 rows of Exchange_Rates:\n",
      "       Date Currency  Exchange\n",
      "0  1/1/2015      USD    1.0000\n",
      "1  1/1/2015      CAD    1.1583\n",
      "2  1/1/2015      AUD    1.2214\n",
      "3  1/1/2015      EUR    0.8237\n",
      "4  1/1/2015      GBP    0.6415\n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11215 entries, 0 to 11214\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      11215 non-null  object \n",
      " 1   Currency  11215 non-null  object \n",
      " 2   Exchange  11215 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 263.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# loading Exchange_Rates.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:/Users/USER/Desktop/DataSpark_Illuminating_Insights_for_Global_Electronics/Exchange_Rates.csv\"\n",
    "\n",
    "# Method 1: Try common encodings automatically\n",
    "encodings = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df_Exchange_Rates = pd.read_csv(file_path, encoding=encoding)\n",
    "        print(f\"Successfully loaded with {encoding} encoding!\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "\n",
    "# Method 2: Manual encoding specification (if automatic fails)\n",
    "# df_Stores = pd.readf_Exchange_Ratesd_csv(file_path, encoding='latin1')  # Most reliable fallback\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(\"\\nFirst 5 rows of Exchange_Rates:\")\n",
    "print(df_Exchange_Rates.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df_Exchange_Rates.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded with utf-8 encoding!\n",
      "\n",
      "First 5 rows of df_Sales:\n",
      "   Order Number  Line Item Order Date Delivery Date  CustomerKey  StoreKey  \\\n",
      "0        366000          1   1/1/2016           NaN       265598        10   \n",
      "1        366001          1   1/1/2016     1/13/2016      1269051         0   \n",
      "2        366001          2   1/1/2016     1/13/2016      1269051         0   \n",
      "3        366002          1   1/1/2016     1/12/2016       266019         0   \n",
      "4        366002          2   1/1/2016     1/12/2016       266019         0   \n",
      "\n",
      "   ProductKey  Quantity Currency Code  \n",
      "0        1304         1           CAD  \n",
      "1        1048         2           USD  \n",
      "2        2007         1           USD  \n",
      "3        1106         7           CAD  \n",
      "4         373         1           CAD  \n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62884 entries, 0 to 62883\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Order Number   62884 non-null  int64 \n",
      " 1   Line Item      62884 non-null  int64 \n",
      " 2   Order Date     62884 non-null  object\n",
      " 3   Delivery Date  13165 non-null  object\n",
      " 4   CustomerKey    62884 non-null  int64 \n",
      " 5   StoreKey       62884 non-null  int64 \n",
      " 6   ProductKey     62884 non-null  int64 \n",
      " 7   Quantity       62884 non-null  int64 \n",
      " 8   Currency Code  62884 non-null  object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 4.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# loading Sales.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:/Users/USER/Desktop/DataSpark_Illuminating_Insights_for_Global_Electronics/Sales.csv\"\n",
    "\n",
    "# Method 1: Try common encodings automatically\n",
    "encodings = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df_Sales = pd.read_csv(file_path, encoding=encoding)\n",
    "        print(f\"Successfully loaded with {encoding} encoding!\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "\n",
    "# Method 2: Manual encoding specification (if automatic fails)\n",
    "# df_Products = pd.read_csv(file_path, encoding='latin1')  # Most reliable fallback\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(\"\\nFirst 5 rows of df_Sales:\")\n",
    "print(df_Sales.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df_Sales.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical/text columns to string\n",
    "df_Customers[\"Gender\"] = df_Customers[\"Gender\"].astype(\"string\")\n",
    "df_Customers[\"Name\"] = df_Customers[\"Name\"].astype(\"string\")\n",
    "df_Customers[\"City\"] = df_Customers[\"City\"].astype(\"string\")\n",
    "df_Customers[\"State\"] = df_Customers[\"State\"].astype(\"string\")\n",
    "df_Customers[\"Country\"] = df_Customers[\"Country\"].astype(\"string\")\n",
    "df_Customers[\"Continent\"] = df_Customers[\"Continent\"].astype(\"string\")\n",
    "df_Customers[\"State Code\"] = df_Customers[\"State Code\"].astype(\"string\")\n",
    "df_Customers[\"Zip Code\"] = df_Customers[\"Zip Code\"].astype(\"string\")\n",
    "\n",
    "# Convert Birthday to datetime format\n",
    "df_Customers[\"Birthday\"] = pd.to_datetime(df_Customers[\"Birthday\"], format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "\n",
    "# Verify the changes\n",
    "print(df_Customers.dtypes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
